# Weighted Word Embedding Textrank

## About This Repository
This paper discusses the use of word weights with TF-IDF and word embedding in the textrank algorithm.
The word embedding model used is:
1) Word2vec (Skipgram)
2) FastText (Skipgram)
3) BERT (Feature-extraction)

## How to use:
1) Download the wikipedia corpus in the make_model folder
2) Run make_model.ipynb to create a word embedding model
3) Download the liputan6 dataset
4) Run the task summarization in the models folder